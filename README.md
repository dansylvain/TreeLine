# TreeLine AI Customer Support Agent

TreeLine is an AI-powered customer support agent built with modern technologies including FastAPI, LangChain, ChromaDB, and Streamlit. It provides intelligent customer support through a retrieval-augmented generation (RAG) pipeline that can answer questions based on your knowledge base.

## ğŸŒ² Features

- **AI-Powered Responses**: Uses OpenAI GPT-4 Turbo for natural language understanding and generation
- **RAG Pipeline**: Retrieval-augmented generation with ChromaDB vector store for knowledge retrieval
- **FastAPI Backend**: High-performance async API with automatic documentation
- **PostgreSQL Database**: Reliable conversation storage and history
- **Streamlit UI**: Clean, intuitive web interface for customer interactions
- **Docker Compose**: Easy deployment and development setup
- **Comprehensive Testing**: Unit tests for all components with pytest
- **Code Quality**: Linting and formatting with ruff and black

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit UI  â”‚â”€â”€â”€â”€â”‚  FastAPI Backend â”‚â”€â”€â”€â”€â”‚   AI Agent      â”‚
â”‚   (Port 8501)   â”‚    â”‚   (Port 8000)    â”‚    â”‚   (Port 8001)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â”‚                        â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   PostgreSQL    â”‚    â”‚    ChromaDB     â”‚
                       â”‚   (Port 5432)   â”‚    â”‚  Vector Store   â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Docker and Docker Compose
- OpenAI API key
- Git

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/TreeLine.git
cd TreeLine
```

### 2. Environment Setup

Copy the example environment file and configure it:

```bash
cp .env.example .env
```

Edit `.env` and add your OpenAI API key:

```env
OPENAI_API_KEY=your_openai_api_key_here
```

### 3. Start the Application

Use the development script to start all services:

```bash
chmod +x dev.sh
./dev.sh start
```

This will:
- Start PostgreSQL database
- Start the FastAPI backend
- Start the AI agent service
- Start the Streamlit UI
- Load sample knowledge base documents

### 4. Access the Application

- **Streamlit UI**: http://localhost:8501
- **FastAPI Backend**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs
- **AI Agent Service**: http://localhost:8001

## ğŸ“ Project Structure

```
TreeLine/
â”œâ”€â”€ backend/                 # FastAPI backend service
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/            # API routes
â”‚   â”‚   â”œâ”€â”€ core/           # Configuration and database
â”‚   â”‚   â”œâ”€â”€ models/         # SQLAlchemy models
â”‚   â”‚   â””â”€â”€ schemas/        # Pydantic schemas
â”‚   â”œâ”€â”€ tests/              # Backend tests
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ ai_agent/               # AI agent service
â”‚   â”œâ”€â”€ agent/              # Core agent logic
â”‚   â”‚   â”œâ”€â”€ core.py         # Main agent class
â”‚   â”‚   â”œâ”€â”€ rag_pipeline.py # RAG implementation
â”‚   â”‚   â””â”€â”€ vector_store.py # ChromaDB management
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ knowledge_base/ # Knowledge documents
â”‚   â”‚   â””â”€â”€ vector_db/      # ChromaDB storage
â”‚   â”œâ”€â”€ tests/              # Agent tests
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ ui/                     # Streamlit user interface
â”‚   â”œâ”€â”€ components/         # UI components
â”‚   â”œâ”€â”€ tests/              # UI tests
â”‚   â”œâ”€â”€ .streamlit/         # Streamlit configuration
â”‚   â”œâ”€â”€ streamlit_app.py    # Main UI application
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yml      # Docker services configuration
â”œâ”€â”€ dev.sh                  # Development script
â”œâ”€â”€ pyproject.toml          # Python project configuration
â”œâ”€â”€ .env.example            # Environment variables template
â””â”€â”€ README.md
```

## ğŸ› ï¸ Development

### Development Commands

The `dev.sh` script provides convenient commands for development:

```bash
# Start all services
./dev.sh start

# Stop all services
./dev.sh stop

# Restart all services
./dev.sh restart

# Check service status and health
./dev.sh status

# View logs
./dev.sh logs [service_name]

# Open services in browser
./dev.sh open

# Run tests
./dev.sh test

# Format code
./dev.sh format

# Clean up (remove containers and volumes)
./dev.sh clean

# Show help
./dev.sh help
```

### Adding Knowledge Base Documents

1. Add your documents (`.txt`, `.md`, or `.json` files) to `ai_agent/data/knowledge_base/`
2. Restart the AI agent service:
   ```bash
   ./dev.sh restart ai-agent
   ```

The agent will automatically load and index the new documents.

### Running Tests

Run all tests:
```bash
./dev.sh test
```

Run specific component tests:
```bash
# Backend tests
cd backend && python -m pytest

# AI agent tests
cd ai_agent && python -m pytest

# UI tests
cd ui && python -m pytest
```

### Code Quality

Format code:
```bash
./dev.sh format
```

Lint code:
```bash
./dev.sh lint
```

## ğŸ”§ Configuration

### Environment Variables

Key environment variables in `.env`:

```env
# OpenAI Configuration
OPENAI_API_KEY=your_api_key_here
LLM_MODEL=gpt-4-turbo
EMBEDDING_MODEL=text-embedding-ada-002
TEMPERATURE=0.7
MAX_TOKENS=1000

# Database Configuration
POSTGRES_USER=treeline
POSTGRES_PASSWORD=treeline_password
POSTGRES_DB=treeline
DATABASE_URL=postgresql+asyncpg://treeline:treeline_password@db:5432/treeline

# Service URLs
BACKEND_URL=http://backend:8000
AI_AGENT_URL=http://ai-agent:8001

# ChromaDB Configuration
CHROMA_PERSIST_DIRECTORY=./data/vector_db
COLLECTION_NAME=treeline_knowledge_base
```

### Customizing the AI Agent

Edit `ai_agent/agent/rag_pipeline.py` to customize:
- Prompt templates
- Response generation logic
- Knowledge retrieval parameters

### Customizing the UI

Edit `ui/streamlit_app.py` and `ui/components/` to customize:
- UI layout and styling
- Chat interface behavior
- Additional features

## ğŸ“Š API Documentation

The FastAPI backend provides automatic API documentation:

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Key Endpoints

- `POST /api/chat` - Send a message to the AI agent
- `GET /api/chat/history/{session_id}` - Get chat history
- `GET /health` - Health check
- `GET /` - API information

## ğŸ§ª Testing

The project includes comprehensive tests:

- **Backend Tests**: API endpoints, database models, business logic
- **AI Agent Tests**: RAG pipeline, vector store, agent responses
- **UI Tests**: Component rendering, user interactions

Run tests with coverage:
```bash
./dev.sh test --coverage
```

## ğŸš¢ Deployment

### Production Deployment

1. Set production environment variables
2. Use production-ready database (not the development PostgreSQL)
3. Configure proper secrets management
4. Set up reverse proxy (nginx) for the UI
5. Enable HTTPS
6. Configure monitoring and logging

### Docker Production Build

```bash
# Build production images
docker-compose -f docker-compose.prod.yml build

# Start production services
docker-compose -f docker-compose.prod.yml up -d
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes
4. Run tests: `./dev.sh test`
5. Format code: `./dev.sh format`
6. Commit changes: `git commit -m 'Add amazing feature'`
7. Push to branch: `git push origin feature/amazing-feature`
8. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“š Documentation

- **[API Endpoints](docs/api-endpoints.md)**: Comprehensive API documentation with examples
- **[Development Guide](docs/development-guide.md)**: Best practices, coding standards, and workflow
- **[Code Review Observations](docs/code-review-observations.md)**: Code quality analysis and future improvements
- **[Database Initialization](docs/database-initialization.md)**: Database setup and schema information

## ğŸ†˜ Support

- **Documentation**: Check this README and the docs/ directory
- **Issues**: Open an issue on GitHub
- **Discussions**: Use GitHub Discussions for questions

## ğŸ™ Acknowledgments

- **OpenAI** for GPT-4 and embedding models
- **LangChain** for LLM orchestration framework
- **ChromaDB** for vector database
- **FastAPI** for the high-performance backend
- **Streamlit** for the intuitive UI framework
- **PostgreSQL** for reliable data storage

---

Built with â¤ï¸ for better customer support experiences.
